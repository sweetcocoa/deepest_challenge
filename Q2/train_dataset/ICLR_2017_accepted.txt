Making Neural Programming Architectures Generalize via Recursion	Jonathon Cai, Richard Shin, Dawn Song
End-to-end Optimized Image Compression	Johannes Ballé, Valero Laparra, Eero P. Simoncelli
Optimization as a Model for Few-Shot Learning	Sachin Ravi, Hugo Larochelle
Learning End-to-End Goal-Oriented Dialog	Antoine Bordes, Y-Lan Boureau, Jason Weston
Towards Principled Methods for Training Generative Adversarial Networks	Martin Arjovsky, Leon Bottou
Reinforcement Learning with Unsupervised Auxiliary Tasks	Max Jaderberg, Volodymyr Mnih, Wojciech Marian Czarnecki, Tom Schaul, Joel Z Leibo, David Silver, Koray Kavukcuoglu
Multi-Agent Cooperation and the Emergence of (Natural) Language	Angeliki Lazaridou, Alexander Peysakhovich, Marco Baroni
Understanding deep learning requires rethinking generalization	Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, Oriol Vinyals
Neural Architecture Search with Reinforcement Learning	Barret Zoph, Quoc Le
Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic	Shixiang Gu, Timothy Lillicrap, Zoubin Ghahramani, Richard E. Turner, Sergey Levine
Learning to Act by Predicting the Future	Alexey Dosovitskiy, Vladlen Koltun
On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima	Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, Ping Tak Peter Tang
Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data	Nicolas Papernot, Martín Abadi, Úlfar Erlingsson, Ian Goodfellow, Kunal Talwar
Amortised MAP Inference for Image Super-resolution	Casper Kaae Sønderby, Jose Caballero, Lucas Theis, Wenzhe Shi, Ferenc Huszár
Learning Graphical State Transitions	Daniel D. Johnson
Maximum Entropy Flow Networks	Gabriel Loaiza-Ganem *, Yuanjun Gao *, John P. Cunningham
Topology and Geometry of Half-Rectified Network Optimization	C. Daniel Freeman, Joan Bruna
Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer	Sergey Zagoruyko, Nikos Komodakis
Learning Visual Servoing with Deep Features and Fitted Q-Iteration	Alex X. Lee, Sergey Levine, Pieter Abbeel
Stochastic Neural Networks for Hierarchical Reinforcement Learning	Carlos Florensa, Yan Duan, Pieter Abbeel
Nonparametric Neural Networks	George Philipp, Jaime G. Carbonell
Distributed Second-Order Optimization using Kronecker-Factored Approximations	Jimmy Ba, Roger Grosse, James Martens
Pruning Filters for Efficient ConvNets	Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, Hans Peter Graf
Learning to Generate Samples from Noise through Infusion Training	Florian Bordes, Sina Honari, Pascal Vincent
FILTER SHAPING FOR CONVOLUTIONAL NEURAL NETWORKS	Xingyi Li, Fuxin Li, Xiaoli Fern, Raviv Raich
Normalizing the Normalizers: Comparing and Extending Network Normalization Schemes	Mengye Ren, Renjie Liao, Raquel Urtasun, Fabian H. Sinz, Richard S. Zemel
Multilayer Recurrent Network Models of Primate Retinal Ganglion Cell Responses	Eleanor Batty, Josh Merel, Nora Brackbill, Alexander Heitman, Alexander Sher, Alan Litke, E.J. Chichilnisky, Liam Paninski
Improving Generative Adversarial Networks with Denoising Feature Matching	David Warde-Farley, Yoshua Bengio
Efficient Vector Representation for Documents through Corruption	Minmin Chen
Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning	Abhishek Gupta, Coline Devin, YuXuan Liu, Pieter Abbeel, Sergey Levine
Transfer of View-manifold Learning to Similarity Perception of Novel Objects	Xingyu Lin, Hao Wang, Zhihao Li, Yimeng Zhang, Alan Yuille, Tai Sing Lee
What does it take to generate natural textures?	Ivan Ustyuzhaninov *, Wieland Brendel *, Leon Gatys, Matthias Bethge
Emergence of foveal image sampling from learning to attend in visual scenes	Brian Cheung, Eric Weiss, Bruno Olshausen
An Information-Theoretic Framework for Fast and Robust Unsupervised Learning via Neural Population Infomax	Wentao Huang, Kechen Zhang
PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications	Tim Salimans, Andrej Karpathy, Xi Chen, Diederik P. Kingma
Mode Regularized Generative Adversarial Networks	Tong Che, Yanran Li, Athul Jacob, Yoshua Bengio, Wenjie Li
Highway and Residual Networks learn Unrolled Iterative Estimation	Klaus Greff, Rupesh K. Srivastava, Jürgen Schmidhuber
Improving Neural Language Models with a Continuous Cache	Edouard Grave, Armand Joulin, Nicolas Usunier
Unsupervised Cross-Domain Image Generation	Yaniv Taigman, Adam Polyak, Lior Wolf
Third Person Imitation Learning	Bradly C Stadie, Pieter Abbeel, Ilya Sutskever
Variational Recurrent Adversarial Deep Domain Adaptation	Sanjay Purushotham, Wilka Carvalho, Tanachat Nilanon, Yan Liu
Program Synthesis for Character Level Language Modeling	Pavol Bielik, Veselin Raychev, Martin Vechev
Episodic Exploration for Deep Deterministic Policies for StarCraft Micromanagement	Nicolas Usunier, Gabriel Synnaeve, Zeming Lin, Soumith Chintala
Soft Weight-Sharing for Neural Network Compression	Karen Ullrich, Edward Meeds, Max Welling
Neural Program Lattices	Chengtao Li, Daniel Tarlow, Alexander L. Gaunt, Marc Brockschmidt, Nate Kushman
Tracking the World State with Recurrent Entity Networks	Mikael Henaff, Jason Weston, Arthur Szlam, Antoine Bordes, Yann LeCun
Steerable CNNs	Taco S. Cohen, Max Welling
Learning to Query, Reason, and Answer Questions On Ambiguous Texts	Xiaoxiao Guo, Tim Klinger, Clemens Rosenbaum, Joseph P. Bigus, Murray Campbell, Ban Kawas, Kartik Talamadupula, Gerry Tesauro, Satinder Singh
Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning	William Lotter, Gabriel Kreiman, David Cox
Diet Networks: Thin Parameters for Fat Genomics	Adriana Romero, Pierre Luc Carrier, Akram Erraqabi, Tristan Sylvain, Alex Auvolat, Etienne Dejoie, Marc-André Legault, Marie-Pierre Dubé, Julie G. Hussin, Yoshua Bengio
Deep Biaffine Attention for Neural Dependency Parsing	Timothy Dozat, Christopher D. Manning
PixelVAE: A Latent Variable Model for Natural Images	Ishaan Gulrajani, Kundan Kumar, Faruk Ahmed, Adrien Ali Taiga, Francesco Visin, David Vazquez, Aaron Courville
Snapshot Ensembles: Train 1, Get M for Free	Gao Huang, Yixuan Li, Geoff Pleiss, Zhuang Liu, John E. Hopcroft, Kilian Q. Weinberger
Training Agent for First-Person Shooter Game with Actor-Critic Curriculum Learning	Yuxin Wu, Yuandong Tian
Neuro-Symbolic Program Synthesis	Emilio Parisotto, Abdel-rahman Mohamed, Rishabh Singh, Lihong Li, Dengyong Zhou, Pushmeet Kohli
Decomposing Motion and Content for Natural Video Sequence Prediction	Ruben Villegas, Jimei Yang, Seunghoon Hong, Xunyu Lin, Honglak Lee
Towards a Neural Statistician	Harrison Edwards, Amos Storkey
Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy	Dougal J. Sutherland, Hsiao-Yu Tung, Heiko Strathmann, Soumyajit De, Aaditya Ramdas, Alex Smola, Arthur Gretton
Generalizing Skills with Semi-Supervised Reinforcement Learning	Chelsea Finn, Tianhe Yu, Justin Fu, Pieter Abbeel, Sergey Levine
Learning Curve Prediction with Bayesian Neural Networks	Aaron Klein, Stefan Falkner, Jost Tobias Springenberg, Frank Hutter
Learning to Optimize	Ke Li, Jitendra Malik
A Compare-Aggregate Model for Matching Text Sequences	Shuohang Wang, Jing Jiang
Data Noising as Smoothing in Neural Network Language Models	Ziang Xie, Sida I. Wang, Jiwei Li, Daniel Lévy, Aiming Nie, Dan Jurafsky, Andrew Y. Ng
Training Compressed Fully-Connected Networks with a Density-Diversity Penalty	Shengjie Wang, Haoran Cai, Jeff Bilmes, William Noble
Autoencoding Variational Inference For Topic Models	Akash Srivastava, Charles Sutton
Optimal Binary Autoencoding with Pairwise Correlations	Akshay Balsubramani
On the Quantitative Analysis of Decoder-Based Generative Models	Yuhuai Wu, Yuri Burda, Ruslan Salakhutdinov, Roger Grosse
Trained Ternary Quantization	Chenzhuo Zhu, Song Han, Huizi Mao, William J. Dally
DSD: Dense-Sparse-Dense Training for Deep Neural Networks	Song Han, Jeff Pool, Sharan Narang, Huizi Mao, Enhao Gong, Shijian Tang, Erich Elsen, Peter Vajda, Manohar Paluri, John Tran, Bryan Catanzaro, William J. Dally
A Compositional Object-Based Approach to Learning Physical Dynamics	Michael Chang, Tomer Ullman, Antonio Torralba, Joshua Tenenbaum
Learning to Remember Rare Events	Lukasz Kaiser, Ofir Nachum, Aurko Roy, Samy Bengio
Transfer Learning for Sequence Tagging with Hierarchical Recurrent Networks	Zhilin Yang, Ruslan Salakhutdinov, William W. Cohen
Words or Characters? Fine-grained Gating for Reading Comprehension	Zhilin Yang, Bhuwan Dhingra, Ye Yuan, Junjie Hu, William W. Cohen, Ruslan Salakhutdinov
A Simple but Tough-to-Beat Baseline for Sentence Embeddings	Sanjeev Arora, Yingyu Liang, Tengyu Ma
Capacity and Trainability in Recurrent Neural Networks	Jasmine Collins, Jascha Sohl-Dickstein, David Sussillo
Learning to Perform Physics Experiments via Deep Reinforcement Learning	Misha Denil, Pulkit Agrawal, Tejas D Kulkarni, Tom Erez, Peter Battaglia, Nando de Freitas
Improving Policy Gradient by Exploring Under-appreciated Rewards	Ofir Nachum, Mohammad Norouzi, Dale Schuurmans
Deep Learning with Dynamic Computation Graphs	Moshe Looks, Marcello Herreshoff, DeLesley Hutchins, Peter Norvig
Calibrating Energy-based Generative Adversarial Networks	Zihang Dai, Amjad Almahairi, Philip Bachman, Eduard Hovy, Aaron Courville
Pruning Convolutional Neural Networks for Resource Efficient Inference	Pavlo Molchanov, Stephen Tyree, Tero Karras, Timo Aila, Jan Kautz
Query-Reduction Networks for Question Answering	Minjoon Seo, Sewon Min, Ali Farhadi, Hannaneh Hajishirzi
Designing Neural Network Architectures using Reinforcement Learning	Bowen Baker, Otkrist Gupta, Nikhil Naik, Ramesh Raskar
Machine Comprehension Using Match-LSTM and Answer Pointer	Shuohang Wang, Jing Jiang
DeepDSL: A Compilation-based Domain-Specific Language for Deep Learning	Tian Zhao, Xiao Bing Huang, Yu Cao
Bidirectional Attention Flow for Machine Comprehension	Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi
Incorporating long-range consistency in CNN-based texture generation	Guillaume Berger, Roland Memisevic
Dynamic Coattention Networks For Question Answering	Caiming Xiong, Victor Zhong, Richard Socher
SampleRNN: An Unconditional End-to-End Neural Audio Generation Model	Soroush Mehri, Kundan Kumar, Ishaan Gulrajani, Rithesh Kumar, Shubham Jain, Jose Sotelo, Aaron Courville, Yoshua Bengio
Metacontrol for Adaptive Imagination-Based Optimization	Jessica B. Hamrick, Andrew J. Ballard, Razvan Pascanu, Oriol Vinyals, Nicolas Heess, Peter W. Battaglia
Exploring Sparsity in Recurrent Neural Networks	Sharan Narang, Greg Diamos, Shubho Sengupta, Erich Elsen
Lossy Image Compression with Compressive Autoencoders	Lucas Theis, Wenzhe Shi, Andrew Cunningham, Ferenc Huszár
Structured Attention Networks	Yoon Kim, Carl Denton, Luong Hoang, Alexander M. Rush
Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations	David Krueger, Tegan Maharaj, Janos Kramar, Mohammad Pezeshki, Nicolas Ballas, Nan Rosemary Ke, Anirudh Goyal, Yoshua Bengio, Aaron Courville, Christopher Pal
Deep Probabilistic Programming	Dustin Tran, Matthew D. Hoffman, Rif A. Saurous, Eugene Brevdo, Kevin Murphy, David M. Blei
LR-GAN: Layered Recursive Generative Adversarial Networks for Image Generation	Jianwei Yang, Anitha Kannan, Dhruv Batra, Devi Parikh
Variational Lossy Autoencoder	Xi Chen, Diederik P. Kingma, Tim Salimans, Yan Duan, Prafulla Dhariwal, John Schulman, Ilya Sutskever, Pieter Abbeel
A recurrent neural network without chaos	Thomas Laurent, James von Brecht
Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer	Noam Shazeer, *Azalia Mirhoseini, *Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, Jeff Dean
Tree-structured decoding with doubly-recurrent neural networks	David Alvarez-Melis, Tommi S. Jaakkola
Introspection:Accelerating Neural Network Training By Learning Weight Evolution	Abhishek Sinha, Aahitagni Mukherjee, Mausoom Sarkar, Balaji Krishnamurthy
Hyperband: Bandit-Based Configuration Evaluation for Hyperparameter Optimization	Lisha Li, Kevin Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, Ameet Talwalkar
Lie-Access Neural Turing Machines	Greg Yang, Alexander Rush
Quasi-Recurrent Neural Networks	James Bradbury, Stephen Merity, Caiming Xiong, Richard Socher
Recurrent Environment Simulators	Silvia Chiappa, Sébastien Racaniere, Daan Wierstra, Shakir Mohamed
EPOpt: Learning Robust Neural Network Policies Using Model Ensembles	Aravind Rajeswaran, Sarvjeet Ghotra, Balaraman Ravindran, Sergey Levine
Attend, Adapt and Transfer: Attentive Deep Architecture for Adaptive Transfer from multiple sources in the same domain	Janarthanan Rajendran, Aravind Lakshminarayanan, Mitesh M. Khapra, Prasanna P, Balaraman Ravindran
Multi-view Recurrent Neural Acoustic Word Embeddings	Wanjia He, Weiran Wang, Karen Livescu
Learning Features of Music From Scratch	John Thickstun, Zaid Harchaoui, Sham Kakade
A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks	Dan Hendrycks, Kevin Gimpel
Learning to superoptimize programs	Rudy Bunel, Alban Desmaison, M. Pawan Kumar, Philip H.S. Torr, Pushmeet Kohli
Trusting SVM for Piecewise Linear CNNs	Leonard Berrada, Andrew Zisserman, M. Pawan Kumar
Sigma Delta Quantized Networks	Peter O'Connor, Max Welling
A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING	Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou, Yoshua Bengio
Regularizing CNNs with Locally Constrained Decorrelations	Pau Rodríguez, Jordi Gonzàlez, Guillem Cucurull, Josep M. Gonfaus, Xavier Roca
The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables	Chris J. Maddison, Andriy Mnih, Yee Whye Teh
Unrolled Generative Adversarial Networks	Luke Metz, Ben Poole, David Pfau, Jascha Sohl-Dickstein
TopicRNN: A Recurrent Neural Network with Long-Range Semantic Dependency	Adji B. Dieng, Chong Wang, Jianfeng Gao, John Paisley
Frustratingly Short Attention Spans in Neural Language Modeling	Michał Daniluk, Tim Rocktäschel, Johannes Welbl, Sebastian Riedel
Recurrent Hidden Semi-Markov Model	Hanjun Dai, Bo Dai, Yan-Ming Zhang, Shuang Li, Le Song
Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data	Maximilian Karl, Maximilian Soelch, Justin Bayer, Patrick van der Smagt
Generative Multi-Adversarial Networks	Ishan Durugkar, Ian Gemp, Sridhar Mahadevan
Mollifying Networks	Caglar Gulcehre, Marcin Moczulski, Francesco Visin, Yoshua Bengio
beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework	Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, Alexander Lerchner
Offline bilingual word vectors, orthogonal transformations and the inverted softmax	Samuel L. Smith, David H. P. Turban, Steven Hamblin, Nils Y. Hammerla
Visualizing Deep Neural Network Decisions: Prediction Difference Analysis	Luisa M Zintgraf, Taco S Cohen, Tameem Adel, Max Welling
Categorical Reparameterization with Gumbel-Softmax	Eric Jang, Shixiang Gu, Ben Poole
Online Bayesian Transfer Learning for Sequential Data Modeling	Priyank Jaini, Zhitang Chen, Pablo Carbajal, Edith Law, Laura Middleton, Kayla Regan, Mike Schaekermann, George Trimponias, James Tung, Pascal Poupart
Latent Sequence Decompositions	William Chan, Yu Zhang, Quoc Le, Navdeep Jaitly
Paleo: A Performance Model for Deep Neural Networks	Hang Qi, Evan R. Sparks, Ameet Talwalkar
Combining policy gradient and Q-learning	Brendan O'Donoghue, Remi Munos, Koray Kavukcuoglu, Volodymyr Mnih
Density estimation using Real NVP	Laurent Dinh, Jascha Sohl-Dickstein, Samy Bengio
Recurrent Batch Normalization	Tim Cooijmans, Nicolas Ballas, César Laurent, Çağlar Gülçehre, Aaron Courville
SGDR: Stochastic Gradient Descent with Warm Restarts	Ilya Loshchilov, Frank Hutter
Learning a Natural Language Interface with Neural Programmer	Arvind Neelakantan, Quoc V. Le, Martin Abadi, Andrew McCallum, Dario Amodei
Reinforcement Learning through Asynchronous Advantage Actor-Critic on a GPU	Mohammad Babaeizadeh, Iuri Frosio, Stephen Tyree, Jason Clemons, Jan Kautz
Learning to Navigate in Complex Environments	Piotr Mirowski, Razvan Pascanu, Fabio Viola, Hubert Soyer, Andy Ballard, Andrea Banino, Misha Denil, Ross Goroshin, Laurent Sifre, Koray Kavukcuoglu, Dharshan Kumaran,Raia Hadsell
DeepCoder: Learning to Write Programs	Matej Balog, Alexander L. Gaunt, Marc Brockschmidt, Sebastian Nowozin, Daniel Tarlow
Learning and Policy Search in Stochastic Dynamical Systems with Bayesian Neural Networks	Stefan Depeweg, José Miguel Hernández-Lobato, Finale Doshi-Velez, Steffen Udluft
Variable Computation in Recurrent Neural Networks	Yacine Jernite, Edouard Grave, Armand Joulin, Tomas Mikolov
Deep Variational Information Bottleneck	Alexander A. Alemi, Ian Fischer, Joshua V. Dillon, Kevin Murphy
The Neural Noisy Channel	Lei Yu, Phil Blunsom, Chris Dyer, Edward Grefenstette, Tomas Kocisky
Automatic Rule Extraction from Long Short Term Memory Networks	W. James Murdoch, Arthur Szlam
Dialogue Learning With Human-in-the-Loop	Jiwei Li, Alexander H. Miller, Sumit Chopra, Marc'Aurelio Ranzato, Jason Weston
Adversarially Learned Inference	Vincent Dumoulin, Ishmael Belghazi, Ben Poole, Alex Lamb, Martin Arjovsky, Olivier Mastropietro, Aaron Courville
Learning through Dialogue Interactions by Asking Questions	Jiwei Li, Alexander H. Miller, Sumit Chopra, Marc'Aurelio Ranzato, Jason Weston
Deep Information Propagation	Samuel S. Schoenholz, Justin Gilmer, Surya Ganguli, Jascha Sohl-Dickstein
FractalNet: Ultra-Deep Neural Networks without Residuals	Gustav Larsson, Michael Maire, Gregory Shakhnarovich
Revisiting Classifier Two-Sample Tests	David Lopez-Paz, Maxime Oquab
Learning to Repeat: Fine Grained Action Repetition for Deep Reinforcement Learning	Sahil Sharma, Aravind S. Lakshminarayanan, Balaraman Ravindran
Loss-aware Binarization of Deep Networks	Lu Hou, Quanming Yao, James T. Kwok
Learning to Play in a Day: Faster Deep Reinforcement Learning by Optimality Tightening	Frank S.He, Yang Liu, Alexander G. Schwing, Jian Peng
Energy-based Generative Adversarial Networks	Junbo Zhao, Michael Mathieu, Yann LeCun
Central Moment Discrepancy (CMD) for Domain-Invariant Representation Learning	Werner Zellinger, Thomas Grubinger, Edwin Lughofer, Thomas Natschläger, Susanne Saminger-Platz
Incremental Network Quantization: Towards Lossless CNNs with Low-precision Weights	Aojun Zhou, Anbang Yao, Yiwen Guo, Lin Xu, Yurong Chen
Entropy-SGD: Biasing Gradient Descent Into Wide Valleys	Pratik Chaudhari, Anna Choromanska, Stefano Soatto, Yann LeCun, Carlo Baldassi, Christian Borgs, Jennifer Chayes, Levent Sagun, Riccardo Zecchina
Deep Multi-task Representation Learning: A Tensor Factorisation Approach	Yongxin Yang, Timothy M. Hospedales
Sample Efficient Actor-Critic with Experience Replay	Ziyu Wang, Victor Bapst, Nicolas Heess, Volodymyr Mnih, Remi Munos, Koray Kavukcuoglu, Nando de Freitas
Temporal Ensembling for Semi-Supervised Learning	Samuli Laine, Timo Aila
On Detecting Adversarial Perturbations	Jan Hendrik Metzen, Tim Genewein, Volker Fischer, Bastian Bischoff
Training deep neural-networks using a noise adaptation layer	Jacob Goldberger, Ehud Ben-Reuven
Learning to Compose Words into Sentences with Reinforcement Learning	Dani Yogatama, Phil Blunsom, Chris Dyer, Edward Grefenstette, Wang Ling
Delving into Transferable Adversarial Examples and Black-box Attacks	Yanpei Liu, Xinyun Chen, Chang Liu, Dawn Song
Identity Matters in Deep Learning	Moritz Hardt, Tengyu Ma
Adversarial Feature Learning	Jeff Donahue, Philipp Krähenbühl, Trevor Darrell
Towards the Limit of Network Quantization	Yoojin Choi, Mostafa El-Khamy, Jungwon Lee
Faster CNNs with Direct Sparse Convolutions and Guided Pruning	Jongsoo Park, Sheng Li, Wei Wen, Ping Tak Peter Tang, Hai Li, Yiran Chen, Pradeep Dubey
Stick-Breaking Variational Autoencoders	Eric Nalisnick, Padhraic Smyth
Batch Policy Gradient Methods for Improving Neural Conversation Models	Kirthevasan Kandasamy, Yoram Bachrach, Ryota Tomioka, Daniel Tarlow, David Carter
Support Regularized Sparse Coding and Its Fast Encoder	Yingzhen Yang, Jiahui Yu, Pushmeet Kohli, Jianchao Yang, Thomas S. Huang
Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling	Hakan Inan, Khashayar Khosravi, Richard Socher
Towards Deep Interpretability (MUS-ROVER II): Learning Hierarchical Representations of Tonal Music	Haizi Yu, Lav R. Varshney
Discrete Variational Autoencoders	Jason Tyler Rolfe
Do Deep Convolutional Nets Really Need to be Deep and Convolutional?	Gregor Urban, Krzysztof J. Geras, Samira Ebrahimi Kahou, Ozlem Aslan, Shengjie Wang, Abdelrahman Mohamed, Matthai Philipose, Matt Richardson, Rich Caruana
Geometry of Polysemy	Jiaqi Mu, Suma Bhat, Pramod Viswanath
Learning Invariant Representations Of Planar Curves	Gautam Pai, Aaron Wetzler, Ron Kimmel
Reasoning with Memory Augmented Neural Networks for Language Comprehension	Tsendsuren Munkhdalai, Hong Yu
Learning Recurrent Representations for Hierarchical Behavior Modeling	Eyrun Eyjolfsdottir, Kristin Branson, Yisong Yue, Pietro Perona
Adversarial Machine Learning at Scale	Alexey Kurakin, Ian J. Goodfellow, Samy Bengio
Predicting Medications from Diagnostic Codes with Recurrent Neural Networks	Jacek M. Bajor, Thomas A. Lasko
Recurrent Mixture Density Network for Spatiotemporal Visual Attention	Loris Bazzani, Hugo Larochelle, Lorenzo Torresani
Inductive Bias of Deep Convolutional Networks through Pooling Geometry	Nadav Cohen, Amnon Shashua
Efficient Representation of Low-Dimensional Manifolds using Deep Networks	Ronen Basri, David W. Jacobs
Semi-Supervised Classification with Graph Convolutional Networks	Thomas N. Kipf, Max Welling
Sparsely-Connected Neural Networks: Towards Efficient VLSI Implementation of Deep Neural Networks	Arash Ardakani, Carlo Condo, Warren J. Gross
Adversarial Training Methods for Semi-Supervised Text Classification	Takeru Miyato, Andrew M. Dai, Ian Goodfellow
Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks	Yossi Adi, Einat Kermany, Yonatan Belinkov, Ofer Lavi, Yoav Goldberg
Pointer Sentinel Mixture Models	Stephen Merity, Caiming Xiong, James Bradbury, Richard Socher
An Actor-Critic Algorithm for Sequence Prediction	Dzmitry Bahdanau, Philemon Brakel, Kelvin Xu, Anirudh Goyal, Ryan Lowe, Joelle Pineau, Aaron Courville, Yoshua Bengio
Understanding Trainable Sparse Coding with Matrix Factorization	Thomas Moreau, Joan Bruna
Tighter bounds lead to improved classifiers	Nicolas Le Roux
HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving	Cezary Kaliszyk, François Chollet, Christian Szegedy
Why Deep Neural Networks for Function Approximation?	Shiyu Liang, R. Srikant
Hierarchical Multiscale Recurrent Neural Networks	Junyoung Chung, Sungjin Ahn, Yoshua Bengio
Neural Photo Editing with Introspective Adversarial Networks	Andrew Brock, Theodore Lim, J.M. Ritchie, Nick Weston
Dropout with Expectation-linear Regularization	Xuezhe Ma, Yingkai Gao, Zhiting Hu, Yaoliang Yu, Yuntian Deng, Eduard Hovy
HyperNetworks	David Ha, Andrew M. Dai, Quoc V. Le
A Learned Representation For Artistic Style	Vincent Dumoulin, Jonathon Shlens, Manjunath Kudlur
Hadamard Product for Low-rank Bilinear Pooling	Jin-Hwa Kim, Kyoung-Woon On, Woosang Lim, Jeonghee Kim, Jung-Woo Ha, Byoung-Tak Zhang
